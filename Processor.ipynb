{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQFam+ReEFGlcLGJvSpMv2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WKhisa/Apache-Spark-DataFrames-Project/blob/main/Processor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZc5_UDSbA1P"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import window, sum, col\n",
        "\n",
        "# Set up Spark session\n",
        "spark = SparkSession.builder.appName(\"NetworkTrafficAnalysis\").getOrCreate()\n",
        "\n",
        "# Read data from the Kafka topic using Structured Streaming\n",
        "df = spark.readStream \\\n",
        "    .format(\"kafka\") \\\n",
        "    .option(\"kafka.bootstrap.servers\", \"broker:29092\") \\\n",
        "    .option(\"subscribe\", \"network-traffic\") \\\n",
        "    .load()\n",
        "\n",
        "# Convert the binary value column to string and split into individual columns\n",
        "df = df.selectExpr(\"CAST(value AS STRING)\") \\\n",
        "    .selectExpr(\n",
        "        \"split(value, ',')[0] AS source_ip\",\n",
        "        \"split(value, ',')[1] AS destination_ip\",\n",
        "        \"CAST(split(value, ',')[2] AS INTEGER) AS bytes_sent\"\n",
        "    )\n",
        "\n",
        "# Perform real-time analytics using stateless transformations\n",
        "processed_df = df \\\n",
        "    .groupBy(\"source_ip\") \\\n",
        "    .agg(sum(\"bytes_sent\").alias(\"total_bytes_sent\"))\n",
        "\n",
        "# Implement sliding window operations and window-based aggregations\n",
        "windowed_df = processed_df \\\n",
        "    .withWatermark(\"timestamp\", \"30 seconds\") \\\n",
        "    .groupBy(\n",
        "        window(\"timestamp\", \"30 seconds\", \"10 seconds\"),\n",
        "        \"source_ip\"\n",
        "    ) \\\n",
        "    .agg(sum(\"total_bytes_sent\").alias(\"windowed_bytes_sent\"))\n",
        "\n",
        "# Write the processed data to the processed-data Kafka topic\n",
        "query = windowed_df \\\n",
        "    .selectExpr(\n",
        "        \"CAST(window.start AS STRING) AS window_start\",\n",
        "        \"CAST(window.end AS STRING) AS window_end\",\n",
        "        \"source_ip\",\n",
        "        \"windowed_bytes_sent\"\n",
        "    ) \\\n",
        "    .writeStream \\\n",
        "    .format(\"kafka\") \\\n",
        "    .option(\"kafka.bootstrap.servers\", \"broker:29092\") \\\n",
        "    .option(\"topic\", \"processed-data\") \\\n",
        "    .outputMode(\"update\") \\\n",
        "    .start()\n",
        "\n",
        "# Wait for the query to terminate\n",
        "query.awaitTermination()\n"
      ]
    }
  ]
}